# Kiáº¿n trÃºc há»‡ thá»‘ng - System Architecture

## Tá»•ng quan / Overview

Silkroad RAG Chatbot sá»­ dá»¥ng kiáº¿n trÃºc RAG (Retrieval-Augmented Generation) vá»›i Gemini FileSearch API.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Frontend (HTML/CSS/JS)        â”‚
â”‚  - Chat Interface                   â”‚
â”‚  - Message Display                  â”‚
â”‚  - User Input                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ HTTP/JSON
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Flask Backend                 â”‚
â”‚  - /api/chat endpoint               â”‚
â”‚  - Session management               â”‚
â”‚  - Chat history                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Gemini API Client               â”‚
â”‚  - Query formatting                 â”‚
â”‚  - FileSearch tool config           â”‚
â”‚  - Response parsing                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Gemini FileSearch Service         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  FileSearch Store             â”‚  â”‚
â”‚  â”‚  - Indexed PDF documents      â”‚  â”‚
â”‚  â”‚  - Embeddings                 â”‚  â”‚
â”‚  â”‚  - Semantic search index      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Gemini LLM                   â”‚  â”‚
â”‚  â”‚  - gemini-2.0-flash-exp       â”‚  â”‚
â”‚  â”‚  - Answer generation          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Luá»“ng hoáº¡t Ä‘á»™ng / Workflow

### 1. Upload & Indexing Phase (Chá»‰ cháº¡y 1 láº§n)

```
PDF Document
    â”‚
    â–¼
[upload_document.py]
    â”‚
    â”œâ”€â–º Create FileSearch Store
    â”‚
    â”œâ”€â–º Upload PDF to Gemini
    â”‚
    â”œâ”€â–º Chunking (800 tokens/chunk)
    â”‚
    â”œâ”€â–º Generate Embeddings
    â”‚
    â””â”€â–º Store in FileSearch Index
```

**Chi tiáº¿t:**

1. **Upload PDF**: File Ä‘Æ°á»£c upload lÃªn Gemini Files API
2. **Chunking**: TÃ i liá»‡u Ä‘Æ°á»£c chia thÃ nh cÃ¡c chunks (~800 tokens má»—i chunk, overlap 100 tokens)
3. **Embedding**: Má»—i chunk Ä‘Æ°á»£c convert thÃ nh embedding vector (1024 dimensions)
4. **Indexing**: Embeddings Ä‘Æ°á»£c lÆ°u vÃ o FileSearch Store vá»›i semantic index
5. **Store ID**: ID cá»§a store Ä‘Æ°á»£c lÆ°u vÃ o `.env` Ä‘á»ƒ sá»­ dá»¥ng sau

### 2. Query Phase (Má»—i khi user há»i)

```
User Question
    â”‚
    â–¼
[Frontend] Send to /api/chat
    â”‚
    â–¼
[Flask Backend]
    â”‚
    â”œâ”€â–º Get session history
    â”‚
    â”œâ”€â–º Build context prompt
    â”‚
    â””â”€â–º Query Gemini API
            â”‚
            â–¼
[Gemini FileSearch]
    â”‚
    â”œâ”€â–º Convert query to embedding
    â”‚
    â”œâ”€â–º Semantic search in FileSearch Store
    â”‚       â”‚
    â”‚       â”œâ”€â–º Find top K relevant chunks (typically K=3-5)
    â”‚       â”‚
    â”‚       â””â”€â–º Compute similarity scores
    â”‚
    â”œâ”€â–º Retrieve relevant document chunks
    â”‚
    â””â”€â–º Pass to LLM with context
            â”‚
            â–¼
[Gemini LLM]
    â”‚
    â”œâ”€â–º Generate answer based on:
    â”‚       - User question
    â”‚       - Retrieved chunks
    â”‚       - Chat history
    â”‚       - System prompt
    â”‚
    â””â”€â–º Return answer + grounding metadata
            â”‚
            â–¼
[Flask Backend]
    â”‚
    â”œâ”€â–º Extract answer text
    â”‚
    â”œâ”€â–º Extract citations
    â”‚
    â”œâ”€â–º Save to chat history
    â”‚
    â””â”€â–º Send JSON response
            â”‚
            â–¼
[Frontend]
    â”‚
    â””â”€â–º Display answer + citations
```

## Components chi tiáº¿t

### 1. Frontend (templates/index.html + static/)

**Nhiá»‡m vá»¥:**
- Hiá»ƒn thá»‹ giao diá»‡n chat
- Gá»­i cÃ¢u há»i qua API
- Nháº­n vÃ  hiá»ƒn thá»‹ cÃ¢u tráº£ lá»i
- Quáº£n lÃ½ UX (typing indicator, scroll, etc.)

**Technologies:**
- Vanilla JavaScript (no frameworks)
- Responsive CSS
- Fetch API cho HTTP requests

### 2. Flask Backend (app.py)

**Endpoints:**

| Endpoint | Method | MÃ´ táº£ |
|----------|--------|-------|
| `/` | GET | Serve HTML page |
| `/api/chat` | POST | Xá»­ lÃ½ cÃ¢u há»i user |
| `/api/history` | GET | Láº¥y lá»‹ch sá»­ chat |
| `/api/clear` | POST | XÃ³a lá»‹ch sá»­ |
| `/api/health` | GET | Health check |

**Features:**
- Session management (UUID-based)
- In-memory chat history (per session)
- Context building tá»« lá»‹ch sá»­
- Error handling

### 3. Gemini FileSearch Integration

**FileSearch Tool Configuration:**

```python
config=types.GenerateContentConfig(
    tools=[
        types.Tool(
            file_search=types.FileSearchTool(
                file_search_store_names=[store_id]
            )
        )
    ],
    temperature=0.2,
    response_modalities=["TEXT"],
)
```

**CÃ¡ch hoáº¡t Ä‘á»™ng:**

1. **Semantic Search**: Gemini tá»± Ä‘á»™ng:
   - Convert cÃ¢u há»i thÃ nh embedding
   - TÃ¬m kiáº¿m trong FileSearch Store
   - Retrieve top relevant chunks

2. **Grounding**: LLM generate cÃ¢u tráº£ lá»i dá»±a trÃªn:
   - Retrieved chunks (RAG context)
   - System prompt
   - Chat history

3. **Citations**: Gemini tráº£ vá» grounding metadata:
   - Document sources
   - Chunk references
   - Confidence scores

## Semantic Search Pipeline

```
User Query: "Silkroad lÃ  gÃ¬?"
    â”‚
    â–¼
Query Embedding
[0.123, -0.456, 0.789, ...]  (1024 dimensions)
    â”‚
    â–¼
Vector Similarity Search
    â”‚
    â”œâ”€â–º Chunk 1: "Silkroad lÃ  má»™t ná»n táº£ng..." (similarity: 0.92)
    â”œâ”€â–º Chunk 2: "Äá»‹nh nghÄ©a Silkroad..." (similarity: 0.88)
    â””â”€â–º Chunk 3: "TÃ­nh nÄƒng cá»§a Silkroad..." (similarity: 0.85)
    â”‚
    â–¼
Top 3 chunks retrieved
    â”‚
    â–¼
LLM Context
"""
System: Báº¡n lÃ  trá»£ lÃ½ AI...
Context:
- Chunk 1: Silkroad lÃ  má»™t ná»n táº£ng...
- Chunk 2: Äá»‹nh nghÄ©a Silkroad...
- Chunk 3: TÃ­nh nÄƒng cá»§a Silkroad...

User: Silkroad lÃ  gÃ¬?
"""
    â”‚
    â–¼
LLM generates answer
"Silkroad lÃ  má»™t ná»n táº£ng..."
```

## Data Flow

### Request Flow

```
1. User Input
   â†“
2. Frontend validates & sends
   POST /api/chat {"message": "..."}
   â†“
3. Flask receives request
   â†“
4. Get/Create session_id
   â†“
5. Load chat history
   â†“
6. Build context prompt
   system_prompt + history + user_question
   â†“
7. Call Gemini API
   gemini_client.models.generate_content(...)
   â†“
8. Gemini FileSearch:
   - Semantic search
   - Retrieve chunks
   - Generate answer
   â†“
9. Parse response
   - Extract answer text
   - Extract citations
   â†“
10. Save to history
    â†“
11. Return JSON
    {"answer": "...", "citations": [...]}
    â†“
12. Frontend displays
```

### Session Management

```python
# In-memory structure
chat_sessions = {
    'session-uuid-1': {
        'messages': [
            {'role': 'user', 'content': '...', 'timestamp': '...'},
            {'role': 'assistant', 'content': '...', 'timestamp': '...'},
        ],
        'created_at': '2024-01-01T10:00:00'
    }
}
```

## Scalability Considerations

### Current Implementation (MVP)
- In-memory session storage
- Single server
- Good for: 10-100 concurrent users

### Recommended Improvements

**1. Session Storage:**
```
In-Memory â†’ Redis
- Distributed sessions
- Persistent across restarts
- Support multiple servers
```

**2. Database:**
```
In-Memory â†’ PostgreSQL/MongoDB
- Store chat history permanently
- User accounts
- Analytics
```

**3. Caching:**
```
Add Redis caching for:
- Frequently asked questions
- Gemini API responses
- Reduce API calls & latency
```

**4. Load Balancing:**
```
nginx â†’ [Flask Server 1]
      â†’ [Flask Server 2]
      â†’ [Flask Server 3]
```

**5. Async Processing:**
```
Flask â†’ FastAPI + async
- Better concurrent handling
- WebSocket support for streaming
```

## Performance Optimization

### Current Performance
- Query latency: ~2-5 seconds (depends on Gemini API)
- Throughput: ~15 requests/minute (API rate limit)

### Optimization Tips

**1. Reduce latency:**
- Use `gemini-2.0-flash-exp` (faster) vs `gemini-2.5-pro`
- Implement response streaming
- Cache common queries

**2. Handle rate limits:**
```python
from tenacity import retry, wait_exponential

@retry(wait=wait_exponential(min=1, max=10))
def query_gemini_with_retry(...):
    # Automatic retry with exponential backoff
    pass
```

**3. Optimize chunking:**
```python
# Experiment with chunk size
chunk_size=800      # Smaller = more precise, more chunks
chunk_size=1200     # Larger = more context, fewer chunks

# Adjust overlap
chunk_overlap=100   # Less overlap = faster indexing
chunk_overlap=200   # More overlap = better retrieval
```

## Security Considerations

### Current Implementation
- Flask secret key (basic session security)
- CORS enabled (development)
- No authentication

### Recommended Improvements

**1. Authentication:**
```python
from flask_login import LoginManager, login_required

@app.route('/api/chat')
@login_required
def chat():
    pass
```

**2. Rate Limiting:**
```python
from flask_limiter import Limiter

limiter = Limiter(app, key_func=get_remote_address)

@app.route('/api/chat')
@limiter.limit("10 per minute")
def chat():
    pass
```

**3. Input Sanitization:**
```python
import bleach

user_message = bleach.clean(user_message)
```

**4. API Key Protection:**
- Use environment variables (âœ“ already done)
- Never expose in client-side code (âœ“ already done)
- Rotate keys regularly

**5. HTTPS:**
- Use SSL/TLS in production
- Configure Flask with proper security headers

## Monitoring & Logging

### Recommended Additions

**1. Logging:**
```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('chatbot.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# Log queries
logger.info(f"User query: {user_message}")
logger.info(f"Response time: {response_time}ms")
```

**2. Metrics:**
- Query count
- Response times
- Error rates
- Popular questions

**3. Alerts:**
- API quota exceeded
- High error rates
- Slow responses

## Cost Estimation

### Gemini API Pricing (Free Tier)

| Resource | Free Tier | Cost After Limit |
|----------|-----------|------------------|
| Storage | 1 GB | Free |
| Indexing | 1M tokens/day | $0.15/1M tokens |
| Queries | 1,500/day | Context tokens pricing |

### Example Usage Cost

**Scenario:** 100 users, 10 questions/user/day

- Total queries: 1,000/day (within free tier âœ“)
- Average response: 500 tokens
- Total tokens: 500K/day (within free tier âœ“)

**Cost: $0/month** (within free tier)

For production scale, estimate ~$10-50/month for 10K queries/day.

## Conclusion

Há»‡ thá»‘ng sá»­ dá»¥ng kiáº¿n trÃºc RAG Ä‘Æ¡n giáº£n nhÆ°ng hiá»‡u quáº£:

âœ… **Æ¯u Ä‘iá»ƒm:**
- Dá»… setup vÃ  maintain
- Chi phÃ­ tháº¥p (miá»…n phÃ­ cho MVP)
- ChÃ­nh xÃ¡c cao (semantic search)
- Há»— trá»£ Ä‘a ngÃ´n ngá»¯ tá»± Ä‘á»™ng

âš ï¸ **Limitations:**
- Single server (for now)
- In-memory storage
- API rate limits
- No authentication

ğŸš€ **Next Steps:**
- Deploy to production
- Add user authentication
- Implement caching
- Monitor vÃ  optimize
