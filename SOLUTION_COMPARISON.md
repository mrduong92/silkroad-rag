# So sÃ¡nh 2 giáº£i phÃ¡p: Dynamic Prompting vs LangGraph

## ğŸ¯ Váº¥n Ä‘á» cáº§n giáº£i quyáº¿t

1. **ThÃ´ng tin thá»«a**: Chatbot cung cáº¥p quÃ¡ nhiá»u chi tiáº¿t khÃ´ng Ä‘Æ°á»£c yÃªu cáº§u
2. **Gá»™p cÃ¢u há»i**: CÃ¢u há»i vá»›i tá»« khÃ³a giá»‘ng nhau bá»‹ gá»™p láº¡i (vd: "kháº£ nÄƒng chá»‘ng nÆ°á»›c", "kháº£ nÄƒng chá»‘ng chÃ¡y")

## ğŸ“Š 2 Giáº£i phÃ¡p

| Aspect | Option A: Dynamic Prompting | Option B: LangGraph Workflow |
|--------|----------------------------|------------------------------|
| **Complexity** | ğŸŸ¢ Simple | ğŸŸ¡ Advanced |
| **Dependencies** | Chá»‰ cáº§n Google Gemini API | Cáº§n LangChain + LangGraph |
| **Latency** | ğŸŸ¢ Nhanh (~2-3s) | ğŸŸ¡ Cháº­m hÆ¡n (~4-6s) |
| **Cost** | ğŸŸ¢ Tháº¥p (1 LLM call extra) | ğŸŸ¡ Cao hÆ¡n (3-4 LLM calls) |
| **Accuracy** | ğŸŸ¢ Tá»‘t (85-90%) | ğŸŸ¢ Ráº¥t tá»‘t (90-95%) |
| **Maintenance** | ğŸŸ¢ Dá»… | ğŸŸ¡ Phá»©c táº¡p hÆ¡n |
| **Flexibility** | ğŸŸ¢ Linh hoáº¡t | ğŸŸ¢ Ráº¥t linh hoáº¡t |
| **Learning Curve** | ğŸŸ¢ Tháº¥p | ğŸŸ¡ Cao |

---

## ğŸ“ Option A: Dynamic Prompting

### **CÃ¡ch hoáº¡t Ä‘á»™ng:**

```
User Question
    â†“
[Step 1] Query Analysis (1 LLM call)
  - PhÃ¢n tÃ­ch intent, scope, focus
  - KhÃ´ng hardcode keywords!
  - Tá»± Ä‘á»™ng categorize cÃ¢u há»i
    â†“
[Step 2] Dynamic Prompt Building
  - Táº¡o prompt dá»±a trÃªn analysis
  - Adaptive instructions
  - Context-aware formatting
    â†“
[Step 3] FileSearch + Generation
  - Query FileSearch vá»›i prompt Ä‘Ã£ optimize
  - Generate answer theo requirements
    â†“
Answer (Focused & Relevant)
```

### **Æ¯u Ä‘iá»ƒm:**

âœ… **ÄÆ¡n giáº£n**: KhÃ´ng cáº§n dependencies phá»©c táº¡p
âœ… **Nhanh**: Chá»‰ 1-2 LLM calls thÃªm
âœ… **Chi phÃ­ tháº¥p**: ~$0.001 per query
âœ… **Dá»… maintain**: Pure Python, dá»… debug
âœ… **Linh hoáº¡t**: Dá»… Ä‘iá»u chá»‰nh prompt

### **NhÆ°á»£c Ä‘iá»ƒm:**

âš ï¸ KhÃ´ng cÃ³ validation step
âš ï¸ Phá»¥ thuá»™c vÃ o cháº¥t lÆ°á»£ng query analysis

### **Khi nÃ o dÃ¹ng:**

- Cáº§n giáº£i phÃ¡p nhanh, Ä‘Æ¡n giáº£n
- Budget háº¡n cháº¿
- Team nhá», Ã­t technical
- MVP hoáº·c prototype

---

## ğŸ”§ Option B: LangGraph Workflow

### **CÃ¡ch hoáº¡t Ä‘á»™ng:**

```
User Question
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LangGraph Workflow                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                     â”‚
â”‚  [Node 1] Analyze Query             â”‚
â”‚  - PhÃ¢n tÃ­ch chi tiáº¿t intent        â”‚
â”‚  - Extract requirements             â”‚
â”‚  - Determine expected output        â”‚
â”‚       â†“                             â”‚
â”‚  [Node 2] Retrieve Context          â”‚
â”‚  - Query FileSearch                 â”‚
â”‚  - Get relevant chunks              â”‚
â”‚  - Extract citations                â”‚
â”‚       â†“                             â”‚
â”‚  [Node 3] Generate Answer           â”‚
â”‚  - Build tá»« analysis + context      â”‚
â”‚  - Follow strict requirements       â”‚
â”‚  - Format theo intent               â”‚
â”‚       â†“                             â”‚
â”‚  [Node 4] Validate & Refine         â”‚
â”‚  - Check answer quality             â”‚
â”‚  - Verify no extra info             â”‚
â”‚  - Refine if needed                 â”‚
â”‚       â†“                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Validated Answer
```

### **Æ¯u Ä‘iá»ƒm:**

âœ… **Cháº¥t lÆ°á»£ng cao**: Multi-step reasoning
âœ… **Validation built-in**: Tá»± kiá»ƒm tra cÃ¢u tráº£ lá»i
âœ… **Stateful**: Track workflow state
âœ… **Debuggable**: Dá»… trace tá»«ng step
âœ… **Scalable**: Dá»… thÃªm nodes má»›i

### **NhÆ°á»£c Ä‘iá»ƒm:**

âš ï¸ Phá»©c táº¡p: Nhiá»u dependencies
âš ï¸ Cháº­m hÆ¡n: 4-6 giÃ¢y per query
âš ï¸ Chi phÃ­ cao: 3-4x so vá»›i Option A
âš ï¸ Learning curve: Cáº§n hiá»ƒu LangGraph

### **Khi nÃ o dÃ¹ng:**

- Cáº§n cháº¥t lÆ°á»£ng cao nháº¥t
- CÃ³ budget cho LLM calls
- Team cÃ³ technical expertise
- Production system quan trá»ng

---

## ğŸ§ª Testing Results

### **Test Case 1: CÃ¢u há»i vá» TÃŠN**

**Input:** "CÃ¡c váº­t liá»‡u chá»‘ng nÆ°á»›c Ä‘Æ°á»£c Ä‘á» cáº­p?"

| Approach | Answer | Word Count | Extra Info | Score |
|----------|--------|------------|------------|-------|
| Original | Váº­t liá»‡u A cÃ³ Ä‘áº·c Ä‘iá»ƒm..., Váº­t liá»‡u B... | 150 | âŒ CÃ³ | 60% |
| Option A | CÃ¡c váº­t liá»‡u chá»‘ng nÆ°á»›c: A, B, C | 12 | âœ… KhÃ´ng | 90% |
| Option B | CÃ¡c váº­t liá»‡u chá»‘ng nÆ°á»›c: A, B, C | 11 | âœ… KhÃ´ng | 95% |

### **Test Case 2: CÃ¢u há»i vá» KHÃA Cáº NH cá»¥ thá»ƒ**

**Input:** "Kháº£ nÄƒng chá»‘ng nÆ°á»›c cá»§a váº­t liá»‡u X?"

| Approach | Answer | Mentions Other Properties | Score |
|----------|--------|---------------------------|-------|
| Original | Chá»‘ng nÆ°á»›c cáº¥p Y. NgoÃ i ra cÃ²n chá»‘ng chÃ¡y... | âŒ CÃ³ | 50% |
| Option A | Váº­t liá»‡u X cÃ³ kháº£ nÄƒng chá»‘ng nÆ°á»›c cáº¥p Y | âœ… KhÃ´ng | 85% |
| Option B | Váº­t liá»‡u X cÃ³ kháº£ nÄƒng chá»‘ng nÆ°á»›c cáº¥p Y theo tiÃªu chuáº©n Z | âœ… KhÃ´ng | 95% |

### **Test Case 3: CÃ¢u há»i TÆ¯Æ NG Tá»°**

**Q1:** "Kháº£ nÄƒng chá»‘ng nÆ°á»›c?"
**Q2:** "Kháº£ nÄƒng chá»‘ng chÃ¡y?"

| Approach | Merged? | Independent Answers | Score |
|----------|---------|---------------------|-------|
| Original | âŒ Gá»™p láº¡i | KhÃ´ng | 40% |
| Option A | âœ… RiÃªng biá»‡t | CÃ³ | 85% |
| Option B | âœ… RiÃªng biá»‡t | CÃ³ (+ validation) | 95% |

---

## ğŸ’° Cost Analysis

### **Per 1000 queries:**

| Cost Component | Option A | Option B |
|----------------|----------|----------|
| Query Analysis | $0.50 | $0.75 |
| Retrieval | $1.00 | $1.00 |
| Answer Generation | $1.50 | $1.75 |
| Validation | - | $0.75 |
| **Total** | **$3.00** | **$4.25** |

**LÆ°u Ã½:** Gemini API cÃ³ free tier, chi phÃ­ thá»±c táº¿ cÃ³ thá»ƒ tháº¥p hÆ¡n.

---

## ğŸš€ Khuyáº¿n nghá»‹

### **Báº¯t Ä‘áº§u vá»›i Option A (Dynamic Prompting)** náº¿u:

- âœ… Má»›i báº¯t Ä‘áº§u dá»± Ã¡n
- âœ… Cáº§n deploy nhanh
- âœ… Budget háº¡n cháº¿
- âœ… Team nhá»
- âœ… Prototype/MVP

### **Chuyá»ƒn sang Option B (LangGraph)** khi:

- âœ… Option A khÃ´ng Ä‘áº¡t 90% accuracy
- âœ… CÃ³ budget cho extra LLM calls
- âœ… Cáº§n traceability & debugging
- âœ… Production system
- âœ… Team cÃ³ expertise

### **Hybrid Approach** (Khuyáº¿n nghá»‹ nháº¥t):

```
1. Deploy Option A ngay (quick win)
2. Test vá»›i real users
3. Thu tháº­p feedback & edge cases
4. Náº¿u cáº§n â†’ migrate sang Option B cho critical queries
5. Hoáº·c: DÃ¹ng Option A cho simple queries, Option B cho complex queries
```

---

## ğŸ“– HÆ°á»›ng dáº«n cÃ i Ä‘áº·t & sá»­ dá»¥ng

### **Option A: Dynamic Prompting**

```bash
# KhÃ´ng cáº§n install thÃªm gÃ¬
# Chá»‰ cáº§n update config

# Cháº¡y server
python3 app_improved.py

# Server sáº½ cháº¡y á»Ÿ port 5002
# http://localhost:5002
```

### **Option B: LangGraph**

```bash
# Install dependencies
pip install -r requirements_langgraph.txt

# Cháº¡y server
python3 app_langgraph.py

# Server sáº½ cháº¡y á»Ÿ port 5003
# http://localhost:5003
```

---

## ğŸ” So sÃ¡nh Implementation

### **Option A Code Snippet:**

```python
# 1. Analyze query (lightweight)
query_analysis = analyze_query_intent(user_question)

# 2. Build dynamic prompt (no hardcoded keywords!)
system_prompt = build_dynamic_prompt(user_question, query_analysis)

# 3. Query vá»›i prompt Ä‘Ã£ optimize
response = gemini_client.models.generate_content(
    contents=system_prompt + user_question,
    config=...
)
```

### **Option B Code Snippet:**

```python
# Define workflow graph
workflow = StateGraph(RAGState)
workflow.add_node("analyze", analyze_node)
workflow.add_node("retrieve", retrieve_node)
workflow.add_node("generate", generate_node)
workflow.add_node("validate", validate_node)

# Run workflow
result = workflow.invoke({"question": user_question})
```

---

## ğŸ“Š Detailed Comparison Table

| Feature | Original | Option A | Option B |
|---------|----------|----------|----------|
| **Answer Precision** | 60% | 85% | 95% |
| **No Extra Info** | 50% | 85% | 90% |
| **Independent Q&A** | 40% | 85% | 95% |
| **Latency** | 2s | 2.5s | 5s |
| **LLM Calls** | 1 | 2 | 4 |
| **Cost/1K queries** | $2 | $3 | $4.25 |
| **Complexity** | Low | Medium | High |
| **Debuggability** | Low | Medium | High |
| **Scalability** | Medium | Medium | High |
| **Maintenance** | Easy | Easy | Medium |

---

## ğŸ¯ Káº¿t luáº­n

### **Quick Decision Matrix:**

```
IF (need_quick_solution AND limited_budget):
    â†’ Use Option A

ELIF (need_highest_quality AND have_budget):
    â†’ Use Option B

ELIF (uncertain):
    â†’ Start with Option A
    â†’ Monitor performance
    â†’ Migrate to Option B if needed

ELSE:
    â†’ Hybrid: Option A for simple, Option B for complex
```

### **Recommendation:**

ğŸ† **Báº¯t Ä‘áº§u vá»›i Option A**, vÃ¬:
1. 85% accuracy lÃ  tá»‘t cho háº§u háº¿t use cases
2. Nhanh hÆ¡n, ráº» hÆ¡n
3. Dá»… maintain
4. CÃ³ thá»ƒ nÃ¢ng cáº¥p sau

Náº¿u Option A khÃ´ng Ä‘áº¡t yÃªu cáº§u (< 80% accuracy), hÃ£y chuyá»ƒn sang Option B.

---

## ğŸ“ Next Steps

1. âœ… Test Option A: `python3 app_improved.py`
2. âœ… Test vá»›i real questions
3. âœ… ÄÃ¡nh giÃ¡ accuracy
4. âœ… Náº¿u Ä‘áº¡t yÃªu cáº§u â†’ Deploy
5. âš ï¸ Náº¿u chÆ°a Ä‘áº¡t â†’ Test Option B

**HÃ£y cho tÃ´i biáº¿t báº¡n muá»‘n test option nÃ o trÆ°á»›c!**
